# Проект для «Викишоп»

## Стек: Python, Pandas, NumPy, Scikit-learn, pattern, nltk

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.
Постройте модель со значением метрики качества F1 не меньше 0.75.

## План работы

1. Загрузить и подготовить данные.
2. Обучить разные модели.
3. Сделать выводы.

## Выводы

Для анализа тональности текстов используются обычно один из двух подходов: классическое ML на основе признаков (мешок слов, n-граммы, tf-idf) либо глубокое обучение на основе языковых моделей. Глубокое обучение более точное, однако, как правило более ресурсо-затратно. Я решил в своём проекте использовать классические методы. В качестве признаков взяты либо вектор на основе мешка слов либо на основе tf-idf. После предварительной очистки и лемматизации датасета были обучены модель на основе логистической регрессии и наивного байесового классификатора.

Логистическая регрессия оказалась лучше для обоих вариантов признаков, однако Байес обучался значительно быстрее чеи логистическая регрессия при оптимальном гиперпараметре, но всё равно логистическая регрессия обучается быстро. Для неё оказался оптимальнеей вектор признаков на основе tf-idf. Эта модель прошла тестирование на тестовом наборе и показала достаточно высокое значение метрики f1.
