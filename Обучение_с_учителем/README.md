# Проект «Отток клиентов»

## Стек: Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn

## Описание проекта

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## План работы

1. Загрузить и подготовить данные.
2. Исследовать баланс классов.
3. Обучить модель без учёта дисбаланса.
4. Улучшить качество модели, учитывая дисбаланс классов.
5. Обучить разные модели и найти лучшую.
6. Описать выводы.
7. Провести финальное тестирование.

## Результаты и выводы

Мы имеем дело с задачей бинарной классификации с сильным дисбалансом классов (4:1).

Рассмотрены разные модели:

1. Классификатор на основе метода k ближайших соседей.
2. Логистическая регрессия.
3. Одиночное решающее дерево.
4. Случайный лес.

Подбор наиболее важных гиперпараметров осуществлён, используя GridSearchCV с методом перекрёстной валидации. Поэтому отдельная валидационная выборк не нужна. Проведено разделения общего набора данных в соотношении обучающего и тестового набора: 4:1 соответственно.

Без учёта дисбаланса не одна из моделей не дотягивает до целевого значения метрики. Есть и аутсайдер - логистическая регрессия.

При использования автоматического взвешивания класса целевая метрика выросла у всех моделей и у случайного леса превысила порог и составила 61.83%.

Техника Downsampling не оправдала себя. При таком простом методе могут быть потеряны наблюдения, несущие полезную информацию, поэтому повышается риск недообучения моделей.

Для техники Upsampling при кросс-валидации результаты по метрики получились лучше, чем при downsampling и сравнимые со взвешиванием классов, однако при тестировании на тестовой выборке и F1 и AUC-ROC хуже, чем у модели со взвешенными классами.
