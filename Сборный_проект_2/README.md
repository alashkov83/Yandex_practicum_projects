# Проект «Восстановление золота из руды»

## Стек: Python, Pandas, NumPy, Scikit-learn, Matplotlib

## Описание проекта

### Постановка задачи

Подготовить прототип модели машинного обучения для «Цифры». Компания разрабатывает решения для эффективной работы промышленных предприятий.
Модель должна предсказать коэффициент восстановления золота из золотосодержащей руды. Модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками.
Нужно:

- Подготовить данные;
- Провести исследовательский анализ данных;
- Построить и обучить модель.

Данные находятся в трёх файлах:

- gold_recovery_train_new.csv — обучающая выборка;
- gold_recovery_test_new.csv — тестовая выборка;
- gold_recovery_full_new.csv — исходные данные.
- 
Данные индексируются датой и временем получения информации (признак date). Соседние по времени параметры часто похожи.
Некоторые параметры недоступны, потому что замеряются и/или рассчитываются значительно позже. Из-за этого в тестовой выборке отсутствуют некоторые признаки, которые могут быть в обучающей. Также в тестовом наборе нет целевых признаков.
Исходный датасет содержит обучающую и тестовую выборки со всеми признаками.


## План работы

1. Подготовить данные-

   - Открыть файлы и изучить их.
   - Проверить, что эффективность обогащения рассчитана правильно. Вычислить её на обучающей выборке для признака rougher.output.recovery. Найти MAE между расчётами и значением признака.
   - Проанализировать признаки, недоступные в тестовой выборке.
   - Провести предобработку данных.

2. Проанализировать данные

   - Определить, как меняется концентрация металлов (Au, Ag, Pb) на различных этапах очистки.
   - Сравнить распределения размеров гранул сырья на обучающей и тестовой выборках.
   - Исследовать суммарную концентрацию всех веществ на разных стадиях: в сырье, в черновом и финальном концентратах.
  
3. Построить модель

   - Написать функцию для вычисления итоговой sMAPE метрики.
   - Обучить разные модели и оценить их качество кросс-валидацией.
   - Выберать лучшую модель и проверить её на тестовой выборке.

## Результаты и выводы

- Файлы открыты штатно. Размерность пространства признаков довольно высока. Некоторые столбцы отсутствуют в тестовой выборки. Имеются пропуски, особенно много в тренировочной выборке. С типами данных проблем нет.
- Категориальных переменных нет. Все переменные, кроме даты, судя по всему относятся к шкале отношений. Желательно шкалирование признаков, так как у них довольно сильно отличаются характеристики разброса. Кое где присутствую выбросы, но не критично.
- Как в тренировочном так и в тестовом наборе встречаются высокоскореллированные признаки. Возможно по ним будет частичная мультиколинеарность которая будет мешать построению моделей (особенно линейных из за высокой погрешности оценки коэффициентов). Это повод либо провести отбор признаков либо применить модели с регуляризацией.
- Определено что, во-первых в тестовом наборе нет признаков output, это целевые признаки, либо признаки напрямую с ними связанные.Во-вторых нет признаков обусловленнных тех. процессом: данные этих признаков рассчитываются позднее (на основании лабораторных анализов образцов) и недоступны во время процесса. Кроме того добавление этих признаков в фичи может спровоцировать утечку целевого признака.
- При анализе изменения концентрации металлов выявлено:

  1. в выходе содержание золота сильно растёт на всех этапах. Немного увеличиватся среднее содержание свинца, в тоже время содержание серебра для этого технологического процесса немного снижается.
  2. в хвостах содержание золота уменьшается после флотации, свинца в хвостах после флотации практически нет. После первого этапа очистки в хвостах растёт сильнее всего концентрация серебра. На второй стадии соотношение концентраций не меняется по сравнению с первой.

- Размеры гранул в двух выборках отличаются не сильно.
- На стадии флотации суммарная концентрация возрастает. На предварительной очистке падает, потом опять возрастает.
- Подбор наиболее важных гиперпараметров осуществлён, используя GridSearchCV с методом перекрёстной валидации. Поэтому отдельная валидационная выборк не нужна. Проведено разделения общего набора данных в соотношении обучающего и тестового набора: 4:1 соответственно.
- Рассмотрены разные модели:

  1. Линейная регрессия.
  2. Гребневая регрессия.
  3. Лассо.
  4. Одиночное решающее дерево.
  5. Случайный лес.

- Все исследованные модели показывают адекватность. Лучше всего справляется с тренировочным набором при кросс-валидации модель случайного леса. Линейные модели хуже.
- Лучшая модель случайного леса провалила испытания на тестовом наборе, а вот гребневая регрессия сработала как и на тренеровочном.
